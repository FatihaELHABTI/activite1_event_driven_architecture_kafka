# Event-Driven Architecture avec Kafka et Spring Cloud Streams

## ğŸ“‹ Table des matiÃ¨res
- [Introduction](#introduction)
- [Concepts fondamentaux](#concepts-fondamentaux)
- [Architecture du projet](#architecture-du-projet)
- [Structure du code](#structure-du-code)
- [Configuration](#configuration)
- [DÃ©marrage du projet](#dÃ©marrage-du-projet)
- [Tests et visualisation](#tests-et-visualisation)
- [Concepts avancÃ©s illustrÃ©s](#concepts-avancÃ©s-illustrÃ©s)
- [Points clÃ©s Ã  retenir](#points-clÃ©s-Ã -retenir)

---

## Introduction

Ce projet dÃ©montre l'implÃ©mentation d'une architecture Ã©vÃ©nementielle (Event-Driven Architecture) utilisant **Apache Kafka** et **Spring Cloud Streams**. Il illustre la production, la consommation et le traitement en temps rÃ©el d'Ã©vÃ©nements de pages web avec visualisation analytique.

### ğŸ¯ Objectifs du projet
- Produire des Ã©vÃ©nements vers des topics Kafka
- Consommer et traiter des Ã©vÃ©nements en temps rÃ©el
- Utiliser Kafka Streams pour l'agrÃ©gation et le windowing
- Visualiser les donnÃ©es analytiques en temps rÃ©el
  ![Analytics en temps rÃ©el](https://raw.githubusercontent.com/FatihaELHABTI/activite1_event_driven_architecture_kafka/main/images/kafka5.png)


---

## Concepts fondamentaux

### ğŸ”¹ Event-Driven Architecture (EDA)
Une architecture pilotÃ©e par les Ã©vÃ©nements oÃ¹ les composants communiquent en Ã©mettant et en consommant des Ã©vÃ©nements de maniÃ¨re asynchrone. Les avantages incluent:
- **DÃ©couplage**: Les producteurs et consommateurs sont indÃ©pendants
- **ScalabilitÃ©**: Chaque composant peut Ãªtre mis Ã  l'Ã©chelle indÃ©pendamment
- **RÃ©silience**: Les Ã©vÃ©nements peuvent Ãªtre rejouÃ©es en cas d'Ã©chec

### ğŸ”¹ Apache Kafka
Plateforme distribuÃ©e de streaming d'Ã©vÃ©nements qui permet:
- **Topics**: Canaux de communication nommÃ©s pour les Ã©vÃ©nements
- **Producers**: Publient des messages vers les topics
- **Consumers**: S'abonnent aux topics pour recevoir les messages
- **Partitions**: Division des topics pour la parallÃ©lisation

### ğŸ”¹ Spring Cloud Streams
Framework qui simplifie le dÃ©veloppement d'applications Ã©vÃ©nementielles en fournissant:
- **Binder**: Abstraction pour se connecter Ã  diffÃ©rents systÃ¨mes de messaging
- **Functional Programming**: Utilisation de `Supplier`, `Consumer`, `Function`
- **Kafka Streams**: Support natif pour le traitement de flux

### ğŸ”¹ Kafka Streams
BibliothÃ¨que de traitement de flux qui permet:
- **Windowing**: Regroupement temporel des Ã©vÃ©nements (tumbling, sliding, session)
- **Aggregations**: Count, sum, reduce sur des fenÃªtres de temps
- **State Stores**: Stockage matÃ©rialisÃ© pour les rÃ©sultats intermÃ©diaires
- **Interactive Queries**: Interrogation des state stores en temps rÃ©el

---

## Architecture du projet

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Kafka Cluster                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ T1   â”‚    â”‚ T2   â”‚    â”‚ T3   â”‚    â”‚ T4   â”‚            â”‚
â”‚  â””â”€â”€â”¬â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”¬â”€â”€â”€â”˜    â””â”€â”€â”¬â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                         â”‚          â”‚
      â”‚                         â”‚          â”‚
â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Application Spring Cloud Streams                   â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ RestController  â”‚  â”‚  PageEventHandler â”‚               â”‚
â”‚  â”‚  - publish()    â”‚  â”‚                   â”‚               â”‚
â”‚  â”‚  - analytics()  â”‚  â”‚  3 Beans:         â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â€¢ Consumer       â”‚               â”‚
â”‚           â”‚           â”‚  â€¢ Supplier       â”‚               â”‚
â”‚           â”‚           â”‚  â€¢ KStream Func   â”‚               â”‚
â”‚           â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚           â”‚                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚  InteractiveQueryService            â”‚                 â”‚
â”‚  â”‚  (count-store)                      â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Frontend     â”‚
                    â”‚  (Smoothie.js)â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flux de donnÃ©es:
1. **T1**: Topic de consommation simple (pageEventConsumer)
2. **T3**: Topic alimentÃ© par le Supplier automatique
3. **T3 â†’ KStream â†’ T4**: Traitement avec filtrage, windowing et agrÃ©gation
4. **count-store**: State store matÃ©rialisÃ© pour les requÃªtes interactives
5. **REST /analytics**: Exposition SSE des donnÃ©es agrÃ©gÃ©es

---

## Structure du code

### 1ï¸âƒ£ **PageEvent.java** - ModÃ¨le d'Ã©vÃ©nement

```java
package ma.enset.kafkaspringcloudstreams.events;

import java.util.Date;

public record PageEvent(String name, String user, Date date, long duration) {
}
```

- **Record Java**: Structure immutable reprÃ©sentant un Ã©vÃ©nement de visite de page
- **Attributs**:
  - `name`: Nom de la page (P1, P2)
  - `user`: Identifiant utilisateur (U1, U2)
  - `date`: Timestamp de l'Ã©vÃ©nement
  - `duration`: DurÃ©e de visite en millisecondes

### 2ï¸âƒ£ **PageEventHandler.java** - Gestion fonctionnelle des Ã©vÃ©nements

```java
package ma.enset.kafkaspringcloudstreams.handlers;

import ma.enset.kafkaspringcloudstreams.events.PageEvent;
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.streams.KeyValue;
import org.apache.kafka.streams.kstream.Grouped;
import org.apache.kafka.streams.kstream.KStream;
import org.apache.kafka.streams.kstream.Materialized;
import org.apache.kafka.streams.kstream.TimeWindows;
import org.springframework.context.annotation.Bean;
import org.springframework.stereotype.Component;

import java.time.Duration;
import java.util.Date;
import java.util.Random;
import java.util.function.Consumer;
import java.util.function.Function;
import java.util.function.Supplier;

@Component
public class PageEventHandler {

    @Bean
    public Consumer<PageEvent> pageEventConsumer(){
        return (input)->{
            System.out.println("***************");
            System.out.println(input.toString());
            System.out.println("***************");
        };
    }

    @Bean
    public Supplier<PageEvent> pageEventSupplier(){
        return ()->{
            return new PageEvent(
                    Math.random()>0.5?"P1":"P2",
                    Math.random()>0.5?"U1":"U2",
                    new Date(),
                    10 +new Random().nextInt(10000)
            );
        };
    }

    @Bean
    public Function<KStream<String, PageEvent>, KStream<String, Long>> KStreamFunction(){
        return (input)->
                input.filter((k,v)->v.duration()>100)
                        .map((k,v)->new KeyValue<>(v.name(),v.duration()))
                        .groupByKey(Grouped.with(Serdes.String(),Serdes.Long()))
                        .windowedBy(TimeWindows.of(Duration.ofSeconds(5)))
                        .count(Materialized.as("count-store"))
                        .toStream()
                        .map((k,v)->new KeyValue<>(k.key(),v));
    }
}
```

#### a) Consumer - Consommation simple
- **Fonction**: Consomme les Ã©vÃ©nements du topic T1
- **Traitement**: Affichage dans la console
- **Binding**: `pageEventConsumer-in-0` â†’ Topic T1

#### b) Supplier - Production automatique
- **Fonction**: GÃ©nÃ¨re des Ã©vÃ©nements toutes les 200ms
- **DonnÃ©es**: PageEvents alÃ©atoires (P1/P2, U1/U2)
- **Binding**: `pageEventSupplier-out-0` â†’ Topic T3

#### c) KStream Function - Traitement avec Kafka Streams

**Pipeline de traitement**:
1. **Filter**: `duration > 100` - Ne garde que les visites significatives
2. **Map**: Transformation en `KeyValue<pageName, duration>`
3. **GroupByKey**: Regroupement par nom de page
4. **WindowedBy**: FenÃªtres de 5 secondes (tumbling window)
5. **Count**: Comptage des Ã©vÃ©nements dans chaque fenÃªtre
6. **Materialized**: Stockage dans "count-store"
7. **ToStream**: Conversion en KStream de sortie

**Concept de Windowing**:
```
Time: 0sâ”€â”€â”€â”€â”€5sâ”€â”€â”€â”€â”€10sâ”€â”€â”€â”€â”€15s
      [Window1][Window2][Window3]
      Events   Events   Events
      â†’ Count  â†’ Count  â†’ Count
```

### 3ï¸âƒ£ **PageEventController.java** - API REST

```java
package ma.enset.kafkaspringcloudstreams.controllers;

import ma.enset.kafkaspringcloudstreams.events.PageEvent;
import org.apache.kafka.streams.KeyValue;
import org.apache.kafka.streams.kstream.Windowed;
import org.apache.kafka.streams.state.KeyValueIterator;
import org.apache.kafka.streams.state.QueryableStoreTypes;
import org.apache.kafka.streams.state.ReadOnlyWindowStore;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.cloud.stream.binder.kafka.streams.InteractiveQueryService;
import org.springframework.cloud.stream.function.StreamBridge;
import org.springframework.http.MediaType;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RestController;
import reactor.core.publisher.Flux;

import java.time.Duration;
import java.time.Instant;
import java.util.Date;
import java.util.HashMap;
import java.util.Map;
import java.util.Random;

@RestController
public class PageEventController {

    @Autowired
    private StreamBridge streamBridge;

    @Autowired
    private InteractiveQueryService interactiveQueryService;

    @GetMapping("/publish")
    public PageEvent publish(String name ,String topic ){
        PageEvent event = new PageEvent(
                name,
                Math.random()>0.5?"U1":"U2",
                new Date(),
                10+new Random().nextInt(100)
        );
        streamBridge.send(topic, event);
        return event;
    }

    @GetMapping(path = "/analytics",produces = MediaType.TEXT_EVENT_STREAM_VALUE)
    public Flux<Map<String, Long>> analytics(){
        return Flux.interval(Duration.ofSeconds(1))
                .map(sequence->{
                    Map<String,Long> stringLongMap=new HashMap<>();
                    ReadOnlyWindowStore<String, Long> windowStore = interactiveQueryService.getQueryableStore("count-store", QueryableStoreTypes.windowStore());
                    Instant now=Instant.now();
                    Instant from=now.minusMillis(5000);
                    KeyValueIterator<Windowed<String>, Long> fetchAll = windowStore.fetchAll(from, now);
                    while (fetchAll.hasNext()){
                        KeyValue<Windowed<String>, Long> next = fetchAll.next();
                        stringLongMap.put(next.key.key(),next.value);
                    }
                    return stringLongMap;
                });
    }
}
```

#### a) Endpoint /publish
- **Fonction**: Publication manuelle d'Ã©vÃ©nements
- **StreamBridge**: Permet d'envoyer dynamiquement vers n'importe quel topic
- **Usage**: `GET /publish?name=P1&topic=T1`

#### b) Endpoint /analytics (Server-Sent Events)

**MÃ©canisme**:
1. **Flux.interval**: Ã‰met un signal chaque seconde
2. **InteractiveQueryService**: RÃ©cupÃ¨re le state store "count-store"
3. **ReadOnlyWindowStore**: Lecture des fenÃªtres temporelles
4. **fetchAll(from, now)**: RÃ©cupÃ¨re les 5 derniÃ¨res secondes
5. **SSE**: Envoie les donnÃ©es au client en temps rÃ©el

**Structure des donnÃ©es retournÃ©es**:
```json
{
  "P1": 12,
  "P2": 8
}
```

### 4ï¸âƒ£ **analytics.html** - Visualisation temps rÃ©el

```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Analytics</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/smoothie/1.34.0/smoothie.min.js"></script>
</head>
<body>

<canvas id="chart2" width="600" height="400"></canvas>
<script>
    var index=-1;
    randomColor = function() {
        ++index;
        if (index >= colors.length) index = 0; return colors[index];
    }
    var pages=["P1","P2"];
    var colors=[
        { sroke : 'rgba(0, 255, 0, 1)', fill : 'rgba(0, 255, 0, 0.2)' },
        { sroke : 'rgba(255, 0, 0, 1)', fill : 'rgba(255, 0, 0, 0.2)'}
    ];
    var courbe = [];
    var smoothieChart = new SmoothieChart({tooltip: true});
    smoothieChart.streamTo(document.getElementById("chart2"), 500);
    pages.forEach(function(v){
        courbe[v]=new TimeSeries();
        col = randomColor();
        smoothieChart.addTimeSeries(courbe[v], {strokeStyle : col.sroke, fillStyle : col.fill, lineWidth : 2
        });
    });
    var stockEventSource= new EventSource("/analytics");
    stockEventSource.addEventListener("message", function (event) {
        pages.forEach(function(v){
            val=JSON.parse(event.data)[v];
            courbe[v].append(new Date().getTime(),val);
        });
    });

</script>
</body>
</html>
```

**Technologies**:
- **SmoothieChart**: BibliothÃ¨que de graphiques en temps rÃ©el
- **EventSource**: API JavaScript pour SSE
- **TimeSeries**: SÃ©ries temporelles pour chaque page

**Fonctionnement**:
1. CrÃ©ation de courbes pour P1 et P2
2. Connexion SSE Ã  `/analytics`
3. Mise Ã  jour du graphique Ã  chaque Ã©vÃ©nement reÃ§u
4. Animation fluide avec interpolation

---

## Configuration

### application.properties

```properties
spring.application.name=kafka-spring-cloud-streams
server.port=8080

# Bindings des fonctions
# Consumer simple
spring.cloud.stream.bindings.pageEventConsumer-in-0.destination=T1

# Supplier automatique
spring.cloud.stream.bindings.pageEventSupplier-out-0.destination=T3
spring.cloud.stream.bindings.pageEventSupplier-out-0.producer.poller.fixed-delay=200

# KStream Function
spring.cloud.stream.bindings.KStreamFunction-in-0.destination=T3
spring.cloud.stream.bindings.KStreamFunction-out-0.destination=T4

# DÃ©claration des fonctions actives
spring.cloud.function.definition=pageEventConsumer;pageEventSupplier;KStreamFunction

# Configuration Kafka Streams
spring.cloud.stream.kafka.streams.binder.configuration.commit.interval.ms=1000
```

**Explication des bindings**:
- Pattern: `<functionName>-<in|out>-<index>`
- `in-0`: PremiÃ¨re entrÃ©e de la fonction
- `out-0`: PremiÃ¨re sortie de la fonction

---

## DÃ©marrage du projet

### PrÃ©requis
- Java 17+
- Docker et Docker Compose
- Maven

### 1ï¸âƒ£ DÃ©marrage de l'infrastructure Kafka

CrÃ©er un fichier `docker-compose.yml`:

```yaml
version: '3'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"

  broker:
    image: confluentinc/cp-kafka:7.3.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
```

Lancer les conteneurs:
```bash
docker-compose up -d
```
![Analytics en temps rÃ©el](https://raw.githubusercontent.com/FatihaELHABTI/activite1_event_driven_architecture_kafka/main/images/kafka1.png)


### 2ï¸âƒ£ VÃ©rification des conteneurs
```bash
docker ps
```
![Analytics en temps rÃ©el](https://raw.githubusercontent.com/FatihaELHABTI/activite1_event_driven_architecture_kafka/main/images/Kafka2.png)

Vous devriez voir:
- `broker` (Kafka) sur le port 9092
- `zookeeper` sur le port 2181

### 3ï¸âƒ£ DÃ©marrage de l'application Spring Boot
```bash
mvn spring-boot:run
```

---

## Tests et visualisation

### Test 1: Console Producer/Consumer

**Producer**:
```bash
docker exec -it broker kafka-console-producer \
  --bootstrap-server broker:9092 \
  --topic R2
```
Taper des messages: `Hello`, `A`, `B`, `C`, `Red`

![Analytics en temps rÃ©el](https://raw.githubusercontent.com/FatihaELHABTI/activite1_event_driven_architecture_kafka/main/images/kafka4.png)


**Consumer**:
```bash
docker exec -it broker kafka-console-consumer \
  --bootstrap-server broker:9092 \
  --topic R2 \
  --from-beginning
```
![Analytics en temps rÃ©el](https://raw.githubusercontent.com/FatihaELHABTI/activite1_event_driven_architecture_kafka/main/images/kafka3.png)


Les messages apparaissent dans l'ordre de rÃ©ception.

### Test 2: Publication manuelle via REST
```bash
curl "http://localhost:8080/publish?name=P1&topic=T1"
curl "http://localhost:8080/publish?name=P2&topic=T3"
```

### Test 3: Visualisation analytique

1. Ouvrir le navigateur: `http://localhost:8080/index.html`
2. Observer les courbes en temps rÃ©el
   - **Courbe verte**: Comptage des Ã©vÃ©nements P1
   - **Courbe rouge**: Comptage des Ã©vÃ©nements P2
3. Les donnÃ©es sont mises Ã  jour chaque seconde via SSE

![Analytics en temps rÃ©el](https://raw.githubusercontent.com/FatihaELHABTI/activite1_event_driven_architecture_kafka/main/images/kafka6.png)


**InterprÃ©tation du graphique**:
- L'axe Y reprÃ©sente le nombre d'Ã©vÃ©nements dans la fenÃªtre de 5 secondes
- L'axe X reprÃ©sente le temps
- Les pics indiquent une activitÃ© intense sur une page

---

## Concepts avancÃ©s illustrÃ©s

### 1. Windowing Tumbling
```
Window 1: [0-5s]  â†’ Count: 10 events
Window 2: [5-10s] â†’ Count: 15 events
Window 3: [10-15s]â†’ Count: 8 events
```
Chaque fenÃªtre est indÃ©pendante, sans chevauchement.

### 2. State Store matÃ©rialisÃ©
Le `count-store` permet:
- Stockage local des agrÃ©gations
- RequÃªtes interactives en temps rÃ©el
- Reconstruction automatique en cas de redÃ©marrage

### 3. Stream Processing Topology
```
Source (T3) â†’ Filter â†’ Map â†’ GroupBy â†’ Window â†’ Count â†’ Sink (T4)
                                              â†“
                                         count-store
```

### 4. Server-Sent Events (SSE)
- Connexion unidirectionnelle serveur â†’ client
- LÃ©ger et natif dans les navigateurs
- IdÃ©al pour les push de donnÃ©es en temps rÃ©el

---

## ğŸ“ Points clÃ©s Ã  retenir

1. **Spring Cloud Streams** simplifie Kafka avec une approche fonctionnelle
2. **Kafka Streams** permet le traitement complexe sans infrastructure externe
3. **Windowing** est essentiel pour l'analyse temporelle
4. **Interactive Queries** transforment Kafka en base de donnÃ©es temps rÃ©el
5. **SSE** est parfait pour les dashboards en temps rÃ©el

---

**Technologies**: Spring Boot, Kafka, Kafka Streams, Spring Cloud Stream, SSE
